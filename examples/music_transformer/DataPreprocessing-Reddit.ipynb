{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from musicautobot.imports import *\n",
    "from musicautobot.numpy_encode import *\n",
    "from musicautobot.config import *\n",
    "from musicautobot.vocab import *\n",
    "from musicautobot.music_transformer.all import *\n",
    "from musicautobot.utils.midifile import *\n",
    "from musicautobot.utils.file_processing import process_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Large Dataset\n",
    "\n",
    "This Notebook is specifically for preprocessing and encoding a large dataset. It uses multi-processing and handles encoding errors\n",
    "\n",
    "***\n",
    "\n",
    "**Note** This is the same training same code as `Train.ipynb`. Only thing that is different is a more robust pre-processing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path('../../data')\n",
    "\n",
    "# Location of your midi files\n",
    "midi_path = base_path/'midi/examples'\n",
    "# Location of preprocessed numpy files\n",
    "numpy_path = base_path/'numpy/lm'\n",
    "\n",
    "# Location of models and cached dataset\n",
    "data_path = base_path/'cached'\n",
    "data_save_name = 'reddit_musicitem_data_save.pkl'\n",
    "\n",
    "[p.mkdir(parents=True, exist_ok=True) for p in [midi_path, numpy_path, data_path]];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gather midi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all your midi data is in `musicautobot/data/midi` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a pretty good dataset with lots of midi data:  \n",
    "https://www.reddit.com/r/datasets/comments/3akhxy/the_largest_midi_collection_on_the_internet/\n",
    "\n",
    "1. Download the folder and unzip it to `data/midi`\n",
    "\n",
    "2. Rename `130000_Pop_...` to `reddit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create dataset from MIDI files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_tracks = [1, 2] # number of tracks to support\n",
    "cutoff = 5 # max instruments\n",
    "min_variation = 3 # minimum number of different midi notes played\n",
    "# max_dur = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "midi_files = get_files(midi_path, '.mid', recurse=True); len(midi_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metadata(midi_file):\n",
    "    # Get outfile and check if it exists\n",
    "    out_file = numpy_path/midi_file.relative_to(midi_path).with_suffix('.npy')\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if out_file.exists(): return\n",
    "    \n",
    "    npenc = transform_midi(midi_file)\n",
    "    if npenc is not None: np.save(out_file, npenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_midi(midi_file, debug=False):\n",
    "    input_path = midi_file\n",
    "    \n",
    "    # Part 1: Filter out midi tracks (drums, repetitive instruments, etc.)\n",
    "    try: \n",
    "#         if duet_only and num_piano_tracks(input_path) not in [1, 2]: return None\n",
    "        input_file = compress_midi_file(input_path, min_variation=min_variation, cutoff=cutoff) # remove non note tracks and standardize instruments\n",
    "        if input_file is None: return None\n",
    "    except Exception as e:\n",
    "        if debug: raise e\n",
    "        if 'badly form' in str(e): return None # ignore badly formatted midi errors\n",
    "        if 'out of range' in str(e): return None # ignore badly formatted midi errors\n",
    "        print('Error parsing midi', input_path, e)\n",
    "        return None\n",
    "        \n",
    "    # Part 2. Compress rests and long notes\n",
    "    stream = file2stream(input_file) # 1.\n",
    "    try:\n",
    "        chordarr = stream2chordarr(stream) # 2. max_dur = quarter_len * sample_freq (4). 128 = 8 bars\n",
    "    except Exception as e:\n",
    "        if debug: raise e\n",
    "        print('Could not encode to chordarr:', input_path, e)\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "    \n",
    "    # Part 3. Compress song rests - Don't want songs with really long pauses \n",
    "    # (this happens because we filter out midi tracks).\n",
    "    chord_trim = trim_chordarr_rests(chordarr)\n",
    "    chord_short = shorten_chordarr_rests(chord_trim)\n",
    "    delta_trim = chord_trim.shape[0] - chord_short.shape[0]\n",
    "#     if delta_trim > 500: \n",
    "#         print(f'Removed {delta_trim} rests from {input_path}. Skipping song')\n",
    "#         return None\n",
    "    chordarr = chord_short\n",
    "    \n",
    "    # Part 3. Chord array to numpy\n",
    "    npenc = chordarr2npenc(chordarr)\n",
    "    if not is_valid_npenc(npenc, input_path=input_path):\n",
    "        return None\n",
    "    \n",
    "    return npenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sanity check\n",
    "import random\n",
    "for r in random.sample(midi_files, 10):\n",
    "#     transform_midi(r, debug=True)\n",
    "    process_metadata(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_func(data, seconds):\n",
    "    print(\"Timeout:\", seconds, data.get('midi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='31' class='' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [31/31 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed = process_all(process_metadata, midi_files, timeout=120, timeout_func=timeout_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_databunch(files, data_save_name, path=data_path):\n",
    "    save_file = path/data_save_name\n",
    "    if save_file.exists():\n",
    "        data = load_data(path, data_save_name)\n",
    "    else:\n",
    "        save_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "        vocab = MusicVocab.create()\n",
    "        processors = [OpenNPFileProcessor(), MusicItemProcessor()]\n",
    "\n",
    "        data = MusicDataBunch.from_files(files, path, processors=processors, encode_position=True)\n",
    "        data.save(data_save_name)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_files = get_files(numpy_path, extensions='.npy', recurse=True); len(numpy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashaw/anaconda3/envs/musicautobot_v1/lib/python3.8/site-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(a, dtype=dtype, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MusicDataBunch;\n",
       "\n",
       "Train: LabelList (28 items)\n",
       "x: MusicItemList\n",
       "\n",
       "MusicItem - (304,)\n",
       "xxbos xxpad n76 d6 n52 d8 n50 d8 n45 d8...,\n",
       "MusicItem - (282,)\n",
       "xxbos xxpad n69 d2 n52 d16 n48 d16 n45 d16...,\n",
       "MusicItem - (134,)\n",
       "xxbos xxpad n57 d2 n52 d16 n48 d16 n45 d16...,\n",
       "MusicItem - (634,)\n",
       "xxbos xxpad n62 d2 n57 d8 n53 d8 n50 d8...,\n",
       "MusicItem - (560,)\n",
       "xxbos xxpad n69 d4 n52 d16 n49 d16 n45 d16...\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: ../../data/cached;\n",
       "\n",
       "Valid: LabelList (3 items)\n",
       "x: MusicItemList\n",
       "\n",
       "MusicItem - (876,)\n",
       "xxbos xxpad n67 d1 n55 d3 n50 d3 n48 d3...,\n",
       "MusicItem - (312,)\n",
       "xxbos xxpad n55 d16 n52 d16 n48 d16 xxsep d4...,\n",
       "MusicItem - (352,)\n",
       "xxbos xxpad xxsep d10 n57 d2 xxsep d2 n59 d2...\n",
       "y: LMLabelList\n",
       ",,\n",
       "Path: ../../data/cached;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = create_databunch(numpy_files, data_save_name=data_save_name); all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "encode_position = True\n",
    "dl_tfms = [batch_position_tfm] if encode_position else []\n",
    "data = load_data(data_path, data_save_name, bs=batch_size, encode_position=encode_position, dl_tfms=dl_tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = default_config()\n",
    "config['encode_position'] = encode_position\n",
    "learn = music_model_learner(data, config=config.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "See [Generate.ipynb](Generate.ipynb) to use a pretrained model and generate better predictions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_file = Path('data/midi/notebook_examples/single_bar_example.mid'); midi_file\n",
    "item = MusicItem.from_file(midi_file, data.vocab);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the seed sounds like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, full = learn.predict(item, n_words=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
