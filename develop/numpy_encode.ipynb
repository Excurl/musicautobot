{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp numpy_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"Encoding music21 streams -> numpy array -> text\"\n",
    "\n",
    "import music21\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "BPB = 4 # beats per bar\n",
    "TIMESIG = f'{BPB}/4' # default time signature\n",
    "PIANO_RANGE = (21, 108)\n",
    "VALTSEP = -1 # separator value for numpy encoding\n",
    "VALTCONT = -2 # numpy value for TCONT - needed for compressing chord array\n",
    "\n",
    "SAMPLE_FREQ = 4\n",
    "NOTE_SIZE = 128\n",
    "DUR_SIZE = (10*BPB*SAMPLE_FREQ)+1 # Max length - 8 bars. Or 16 beats/quarternotes\n",
    "MAX_NOTE_DUR = (8*BPB*SAMPLE_FREQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Encoding process\n",
    "# 1. midi -> music21.Stream\n",
    "# 2. Stream -> numpy chord array (timestep X instrument X noterange)\n",
    "# 3. numpy array -> List[Timestep][NoteEnc]\n",
    "def midi2npenc(midi_file, skip_last_rest=True):\n",
    "    \"Converts midi file to numpy encoding for language model\"\n",
    "    stream = file2stream(midi_file) # 1.\n",
    "    chordarr = stream2chordarr(stream) # 2.\n",
    "    return chordarr2npenc(chordarr, skip_last_rest=skip_last_rest) # 3.\n",
    "\n",
    "# Decoding process\n",
    "# 1. NoteEnc -> numpy chord array\n",
    "# 2. numpy array -> music21.Stream\n",
    "def npenc2stream(arr, bpm=120):\n",
    "    \"Converts numpy encoding to music21 stream\"\n",
    "    chordarr = npenc2chordarr(np.array(arr)) # 1.\n",
    "    return chordarr2stream(chordarr, bpm=bpm) # 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "##### ENCODING ######\n",
    "\n",
    "# 1. File To STream\n",
    "\n",
    "def file2stream(fp):\n",
    "    if isinstance(fp, music21.midi.MidiFile): return music21.midi.translate.midiFileToStream(fp)\n",
    "    return music21.converter.parse(fp)\n",
    "\n",
    "# 2.\n",
    "def stream2chordarr(s, note_size=NOTE_SIZE, sample_freq=SAMPLE_FREQ, max_note_dur=MAX_NOTE_DUR):\n",
    "    \"Converts music21.Stream to 1-hot numpy array\"\n",
    "    # assuming 4/4 time\n",
    "    # note x instrument x pitch\n",
    "    # FYI: midi middle C value=60\n",
    "    \n",
    "    # (AS) TODO: need to order by instruments most played and filter out percussion or include the channel\n",
    "    highest_time = max(s.flat.getElementsByClass('Note').highestTime, s.flat.getElementsByClass('Chord').highestTime)\n",
    "    maxTimeStep = round(highest_time * sample_freq)+1\n",
    "    score_arr = np.zeros((maxTimeStep, len(s.parts), NOTE_SIZE))\n",
    "\n",
    "    def note_data(pitch, note):\n",
    "        return (pitch.midi, int(round(note.offset*sample_freq)), int(round(note.duration.quarterLength*sample_freq)))\n",
    "\n",
    "    for idx,part in enumerate(s.parts):\n",
    "        notes=[]\n",
    "        for elem in part.flat:\n",
    "            if isinstance(elem, music21.note.Note):\n",
    "                notes.append(note_data(elem.pitch, elem))\n",
    "            if isinstance(elem, music21.chord.Chord):\n",
    "                for p in elem.pitches:\n",
    "                    notes.append(note_data(p, elem))\n",
    "                \n",
    "        # sort notes by offset (1), duration (2) so that hits are not overwritten and longer notes have priority\n",
    "        notes_sorted = sorted(notes, key=lambda x: (x[1], x[2])) \n",
    "        for n in notes_sorted:\n",
    "            if n is None: continue\n",
    "            pitch,offset,duration = n\n",
    "            if max_note_dur is not None and duration > max_note_dur: duration = max_note_dur\n",
    "            score_arr[offset, idx, pitch] = duration\n",
    "            score_arr[offset+1:offset+duration, idx, pitch] = VALTCONT      # Continue holding note\n",
    "    return score_arr\n",
    "\n",
    "def chordarr2npenc(chordarr, skip_last_rest=True):\n",
    "    # combine instruments\n",
    "    result = []\n",
    "    wait_count = 0\n",
    "    for idx,timestep in enumerate(chordarr):\n",
    "        flat_time = timestep2npenc(timestep)\n",
    "        if len(flat_time) == 0:\n",
    "            wait_count += 1\n",
    "        else:\n",
    "            # pitch, octave, duration, instrument\n",
    "            if wait_count > 0: result.append([VALTSEP, wait_count])\n",
    "            result.extend(flat_time)\n",
    "            wait_count = 1\n",
    "    if wait_count > 0 and not skip_last_rest: result.append([VALTSEP, wait_count])\n",
    "    return np.array(result, dtype=int).reshape(-1, 2) # reshaping. Just in case result is empty\n",
    "\n",
    "# Note: not worrying about overlaps - as notes will still play. just look tied\n",
    "# http://web.mit.edu/music21/doc/moduleReference/moduleStream.html#music21.stream.Stream.getOverlaps\n",
    "def timestep2npenc(timestep, note_range=PIANO_RANGE, enc_type=None):\n",
    "    # inst x pitch\n",
    "    notes = []\n",
    "    for i,n in zip(*timestep.nonzero()):\n",
    "        d = timestep[i,n]\n",
    "        if d < 0: continue # only supporting short duration encoding for now\n",
    "        if n < note_range[0] or n >= note_range[1]: continue # must be within midi range\n",
    "        notes.append([n,d,i])\n",
    "        \n",
    "    notes = sorted(notes, key=lambda x: x[0], reverse=True) # sort by note (highest to lowest)\n",
    "    \n",
    "    if enc_type is None: \n",
    "        # note, duration\n",
    "        return [n[:2] for n in notes] \n",
    "    if enc_type == 'parts':\n",
    "        # note, duration, part\n",
    "        return [n for n in notes]\n",
    "    if enc_type == 'full':\n",
    "        # note_class, duration, octave, instrument\n",
    "        return [[n%12, d, n//12, i] for n,d,i in notes] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "##### DECODING #####\n",
    "\n",
    "# 1.\n",
    "def npenc2chordarr(npenc, note_size=NOTE_SIZE):\n",
    "    num_instruments = 1 if len(npenc.shape) <= 2 else npenc.max(axis=0)[-1]\n",
    "    \n",
    "    max_len = npenc_len(npenc)\n",
    "    # score_arr = (steps, inst, note)\n",
    "    score_arr = np.zeros((max_len, num_instruments, note_size))\n",
    "    \n",
    "    idx = 0\n",
    "    for step in npenc:\n",
    "        n,d,i = (step.tolist()+[0])[:3] # or n,d,i\n",
    "        if n < VALTSEP: continue # special token\n",
    "        if n == VALTSEP:\n",
    "            idx += d\n",
    "            continue\n",
    "        score_arr[idx,i,n] = d\n",
    "    return score_arr\n",
    "\n",
    "def npenc_len(npenc):\n",
    "    duration = 0\n",
    "    for t in npenc:\n",
    "        if t[0] == VALTSEP: duration += t[1]\n",
    "    return duration + 1\n",
    "\n",
    "\n",
    "# 2.\n",
    "def chordarr2stream(arr, sample_freq=SAMPLE_FREQ, bpm=120):\n",
    "    duration = music21.duration.Duration(1. / sample_freq)\n",
    "    stream = music21.stream.Score()\n",
    "    stream.append(music21.meter.TimeSignature(TIMESIG))\n",
    "    stream.append(music21.tempo.MetronomeMark(number=bpm))\n",
    "    stream.append(music21.key.KeySignature(0))\n",
    "    for inst in range(arr.shape[1]):\n",
    "        p = partarr2stream(arr[:,inst,:], duration)\n",
    "        stream.append(p)\n",
    "    stream = stream.transpose(0)\n",
    "    return stream\n",
    "\n",
    "# 2b.\n",
    "def partarr2stream(partarr, duration):\n",
    "    \"convert instrument part to music21 chords\"\n",
    "    part = music21.stream.Part()\n",
    "    part.append(music21.instrument.Piano())\n",
    "    part_append_duration_notes(partarr, duration, part) # notes already have duration calculated\n",
    "\n",
    "    return part\n",
    "\n",
    "def part_append_duration_notes(partarr, duration, stream):\n",
    "    \"convert instrument part to music21 chords\"\n",
    "    for tidx,t in enumerate(partarr):\n",
    "        note_idxs = np.where(t > 0)[0] # filter out any negative values (continuous mode)\n",
    "        if len(note_idxs) == 0: continue\n",
    "        notes = []\n",
    "        for nidx in note_idxs:\n",
    "            note = music21.note.Note(nidx)\n",
    "            note.duration = music21.duration.Duration(partarr[tidx,nidx]*duration.quarterLength)\n",
    "            notes.append(note)\n",
    "        for g in group_notes_by_duration(notes):\n",
    "            if len(g) == 1:\n",
    "                stream.insert(tidx*duration.quarterLength, g[0])\n",
    "            else:\n",
    "                chord = music21.chord.Chord(g)\n",
    "                stream.insert(tidx*duration.quarterLength, chord)\n",
    "    return stream\n",
    "\n",
    "from itertools import groupby\n",
    "#  combining notes with different durations into a single chord may overwrite conflicting durations. Example: aylictal/still-waters-run-deep\n",
    "def group_notes_by_duration(notes):\n",
    "    \"separate notes into chord groups\"\n",
    "    keyfunc = lambda n: n.duration.quarterLength\n",
    "    notes = sorted(notes, key=keyfunc)\n",
    "    return [list(g) for k,g in groupby(notes, keyfunc)]\n",
    "\n",
    "\n",
    "# Midi -> npenc Conversion helpers\n",
    "def is_valid_npenc(npenc, note_range=PIANO_RANGE, max_dur=DUR_SIZE, \n",
    "                   min_notes=32, input_path=None, verbose=True):\n",
    "    if len(npenc) < min_notes:\n",
    "        if verbose: print('Sequence too short:', len(npenc), input_path)\n",
    "        return False\n",
    "    if (npenc[:,1] >= max_dur).any(): \n",
    "        if verbose: print(f'npenc exceeds max {max_dur} duration:', npenc[:,1].max(), input_path)\n",
    "        return False\n",
    "    # https://en.wikipedia.org/wiki/Scientific_pitch_notation - 88 key range - 21 = A0, 108 = C8\n",
    "    if ((npenc[...,0] > VALTSEP) & ((npenc[...,0] < note_range[0]) | (npenc[...,0] >= note_range[1]))).any(): \n",
    "        print(f'npenc out of piano note range {note_range}:', input_path)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# seperates overlapping notes to different tracks\n",
    "def remove_overlaps(stream, separate_chords=True):\n",
    "    if not separate_chords:\n",
    "        return stream.flat.makeVoices().voicesToParts()\n",
    "    return separate_melody_chord(stream)\n",
    "\n",
    "# seperates notes and chords to different tracks\n",
    "def separate_melody_chord(stream):\n",
    "    new_stream = music21.stream.Score()\n",
    "    if stream.timeSignature: new_stream.append(stream.timeSignature)\n",
    "    new_stream.append(stream.metronomeMarkBoundaries()[0][-1])\n",
    "    if stream.keySignature: new_stream.append(stream.keySignature)\n",
    "    \n",
    "    melody_part = music21.stream.Part(stream.flat.getElementsByClass('Note'))\n",
    "    melody_part.insert(0, stream.getInstrument())\n",
    "    chord_part = music21.stream.Part(stream.flat.getElementsByClass('Chord'))\n",
    "    chord_part.insert(0, stream.getInstrument())\n",
    "    new_stream.append(melody_part)\n",
    "    new_stream.append(chord_part)\n",
    "    return new_stream\n",
    "\n",
    "# processing functions for sanitizing data\n",
    "\n",
    "def compress_chordarr(chordarr):\n",
    "    return shorten_chordarr_rests(trim_chordarr_rests(chordarr))\n",
    "\n",
    "def trim_chordarr_rests(arr, max_rests=4, sample_freq=SAMPLE_FREQ):\n",
    "    # max rests is in quarter notes\n",
    "    # max 1 bar between song start and end\n",
    "    start_idx = 0\n",
    "    max_sample = max_rests*sample_freq\n",
    "    for idx,t in enumerate(arr):\n",
    "        if (t != 0).any(): break\n",
    "        start_idx = idx+1\n",
    "        \n",
    "    end_idx = 0\n",
    "    for idx,t in enumerate(reversed(arr)):\n",
    "        if (t != 0).any(): break\n",
    "        end_idx = idx+1\n",
    "    start_idx = start_idx - start_idx % max_sample\n",
    "    end_idx = end_idx - end_idx % max_sample\n",
    "#     if start_idx > 0 or end_idx > 0: print('Trimming rests. Start, end:', start_idx, len(arr)-end_idx, end_idx)\n",
    "    return arr[start_idx:(len(arr)-end_idx)]\n",
    "\n",
    "def shorten_chordarr_rests(arr, max_rests=8, sample_freq=SAMPLE_FREQ):\n",
    "    # max rests is in quarter notes\n",
    "    # max 2 bar pause\n",
    "    rest_count = 0\n",
    "    result = []\n",
    "    max_sample = max_rests*sample_freq\n",
    "    for timestep in arr:\n",
    "        if (timestep==0).all(): \n",
    "            rest_count += 1\n",
    "        else:\n",
    "            if rest_count > max_sample:\n",
    "#                 old_count = rest_count\n",
    "                rest_count = (rest_count % sample_freq) + max_sample\n",
    "#                 print(f'Compressing rests: {old_count} -> {rest_count}')\n",
    "            for i in range(rest_count): result.append(np.zeros(timestep.shape))\n",
    "            rest_count = 0\n",
    "            result.append(timestep)\n",
    "    for i in range(rest_count): result.append(np.zeros(timestep.shape))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# sequence 2 sequence convenience functions\n",
    "\n",
    "def chordarr_combine_parts(parts):\n",
    "    max_ts = max([p.shape[0] for p in parts])\n",
    "    parts_padded = [pad_part_to(p, max_ts) for p in parts]\n",
    "    chordarr_comb = np.concatenate(parts_padded, axis=1)\n",
    "    return chordarr_comb\n",
    "\n",
    "def pad_part_to(p, target_size):\n",
    "    pad_width = ((0,target_size-p.shape[0]),(0,0),(0,0))\n",
    "    return np.pad(p, pad_width, 'constant')\n",
    "\n",
    "def part_enc(chordarr, part):\n",
    "    partarr = chordarr[:,part:part+1,:]\n",
    "    npenc = chordarr2npenc(partarr)\n",
    "    return npenc\n",
    "\n",
    "def avg_tempo(t, sep_idx=VALTSEP):\n",
    "    avg = t[t[:, 0] == sep_idx][:, 1].sum()/t.shape[0]\n",
    "    avg = int(round(avg/SAMPLE_FREQ))\n",
    "    return 'mt'+str(min(avg, MTEMPO_SIZE-1))\n",
    "\n",
    "def avg_pitch(t, sep_idx=VALTSEP):\n",
    "    return t[t[:, 0] > sep_idx][:, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def is_valid_npenc(npenc, min_notes=9, note_range=PIANO_RANGE, max_dur=DUR_SIZE):\n",
    "    if len(npenc) < min_notes: return False\n",
    "    \n",
    "    if (npenc[:,1] >= max_dur).any(): return False\n",
    "    # https://en.wikipedia.org/wiki/Scientific_pitch_notation - 88 key range - 21 = A0, 108 = C8\n",
    "    if ((npenc[...,0] > VALTSEP) & ((npenc[...,0] < note_range[0]) | (npenc[...,0] >= note_range[1]))).any(): return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted config.ipynb.\n",
      "Converted Train-before_cleanup.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted Train-Scratch.ipynb.\n",
      "Converted dataloader-reference.ipynb.\n",
      "Converted dataloader-v1.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted numpy_encode.ipynb.\n",
      "Converted attention_mask.ipynb.\n",
      "Converted env_setup.ipynb.\n",
      "Converted fastai_transformer.ipynb.\n",
      "Converted file_processing.ipynb.\n",
      "Converted lamb.ipynb.\n",
      "Converted midifile.ipynb.\n",
      "Converted stacked_dataloader.ipynb.\n",
      "Converted top_k_top_p.ipynb.\n",
      "Converted vocab.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
