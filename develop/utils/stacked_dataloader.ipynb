{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.stacked_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"Dataloader wrapper that can combine and handle multiple dataloaders for multitask training\"\n",
    "from fastai.callback.all import Callback\n",
    "from typing import Callable\n",
    "\n",
    "# DataLoading\n",
    "class StackedDataBunch():\n",
    "    def __init__(self, dbs, num_it=100):\n",
    "        self.dbs = dbs\n",
    "        self.train_dl = StackedDataloader([db.train_dl for db in self.dbs], num_it)\n",
    "        self.valid_dl = StackedDataloader([db.valid_dl for db in self.dbs], num_it)\n",
    "        self.train_ds = None\n",
    "        self.path = dbs[0].path\n",
    "        self.device = dbs[0].device\n",
    "        self.vocab = dbs[0].vocab\n",
    "        self.empty_val = False\n",
    "\n",
    "    def add_tfm(self,tfm:Callable)->None:\n",
    "        for dl in self.dbs: dl.add_tfm(tfm)\n",
    "\n",
    "    def remove_tfm(self,tfm:Callable)->None:\n",
    "        for dl in self.dbs: dl.remove_tfm(tfm)\n",
    "\n",
    "# Helper functions\n",
    "class StackedDataset(Callback):\n",
    "    def __init__(self, dss):\n",
    "        self.dss = dss\n",
    "    def __getattribute__(self, attr):\n",
    "        if attr == 'dss': return super().__getattribute__(attr)\n",
    "        def redirected(*args, **kwargs):\n",
    "            for ds in self.dss:\n",
    "                if hasattr(ds, attr): getattr(ds, attr)(*args, **kwargs)\n",
    "        return redirected\n",
    "    def __len__(self)->int: return sum([len(ds) for ds in self.dss])\n",
    "    def __repr__(self): return '\\n'.join([self.__class__.__name__] + [repr(ds) for ds in self.dss])\n",
    "\n",
    "class StackedDataloader():\n",
    "    def __init__(self, dls, num_it=100):\n",
    "        self.dls = dls\n",
    "        self.dataset = StackedDataset([dl.dataset for dl in dls if hasattr(dl, 'dataset')])\n",
    "        self.num_it = num_it\n",
    "        self.dl_idx = -1\n",
    "        \n",
    "    def __len__(self)->int: return sum([len(dl) for dl in self.dls])\n",
    "    def __getattr__(self, attr):\n",
    "        def redirected(*args, **kwargs):\n",
    "            for dl in self.dls:\n",
    "                if hasattr(dl, attr):\n",
    "                    getattr(dl, attr)(*args, **kwargs)\n",
    "        return redirected\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"Process and returns items from `DataLoader`.\"\n",
    "        iters = [iter(dl) for dl in self.dls]\n",
    "        self.dl_idx = -1\n",
    "        while len(iters):\n",
    "            self.dl_idx = (self.dl_idx+1) % len(iters)\n",
    "            for b in range(self.num_it):\n",
    "                try:\n",
    "                    yield next(iters[self.dl_idx])\n",
    "                except StopIteration as e:\n",
    "                    iters.remove(iters[self.dl_idx])\n",
    "                    break\n",
    "#         raise StopIteration\n",
    "\n",
    "    def new(self, **kwargs):\n",
    "        \"Create a new copy of `self` with `kwargs` replacing current values.\"\n",
    "        new_dls = [dl.new(**kwargs) for dl in self.dls]\n",
    "        return StackedDataloader(new_dls, self.num_it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted config.ipynb.\n",
      "Converted Train-before_cleanup.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted Train-Scratch.ipynb.\n",
      "Converted dataloader-reference.ipynb.\n",
      "Converted dataloader-v1.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted numpy_encode.ipynb.\n",
      "Converted attention_mask.ipynb.\n",
      "Converted env_setup.ipynb.\n",
      "Converted fastai_transformer.ipynb.\n",
      "Converted file_processing.ipynb.\n",
      "Converted lamb.ipynb.\n",
      "Converted midifile.ipynb.\n",
      "Converted stacked_dataloader.ipynb.\n",
      "Converted top_k_top_p.ipynb.\n",
      "Converted vocab.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
