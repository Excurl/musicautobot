{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp multitask_transformer.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *\n",
    "from musicautobot.multitask_transformer.transform import *\n",
    "from musicautobot.music_transformer.dataloader import MusicDataBunch, MusicItemList\n",
    "# Sequence 2 Sequence Translate\n",
    "\n",
    "class S2SFileProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that opens the filenames and read the texts.\"\n",
    "    def process_one(self,item):\n",
    "        out = np.load(item, allow_pickle=True)\n",
    "        if out.shape != (2,): return None\n",
    "        if not 16 < len(out[0]) < 2048: return None\n",
    "        if not 16 < len(out[1]) < 2048: return None\n",
    "        return out\n",
    "    \n",
    "    def process(self, ds:Collection):\n",
    "        ds.items = [self.process_one(item) for item in ds.items]\n",
    "        ds.items = [i for i in ds.items if i is not None] # filter out None\n",
    "\n",
    "class S2SPartsProcessor(PreProcessor):\n",
    "    \"Encodes midi file into 2 separate parts - melody and chords.\"\n",
    "    \n",
    "    def process_one(self, item):\n",
    "        m, c = item\n",
    "        mtrack = MultitrackItem.from_npenc_parts(m, c, vocab=self.vocab)\n",
    "        return mtrack.to_idx()\n",
    "    \n",
    "    def process(self, ds):\n",
    "        self.vocab = ds.vocab\n",
    "        ds.items = [self.process_one(item) for item in ds.items]\n",
    "        \n",
    "class Midi2MultitrackProcessor(PreProcessor):\n",
    "    \"Converts midi files to multitrack items\"\n",
    "    def process_one(self, midi_file):\n",
    "        try:\n",
    "            item = MultitrackItem.from_file(midi_file, vocab=self.vocab)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        return item.to_idx()\n",
    "        \n",
    "    def process(self, ds):\n",
    "        self.vocab = ds.vocab\n",
    "        ds.items = [self.process_one(item) for item in ds.items]\n",
    "        ds.items = [i for i in ds.items if i is not None]\n",
    "    \n",
    "class S2SPreloader(Callback):\n",
    "    def __init__(self, dataset:LabelList, bptt:int=512, \n",
    "                 transpose_range=None, **kwargs):\n",
    "        self.dataset,self.bptt = dataset,bptt\n",
    "        self.vocab = self.dataset.vocab\n",
    "        self.transpose_range = transpose_range\n",
    "        self.rand_transpose = partial(rand_transpose_value, rand_range=transpose_range) if transpose_range is not None else None\n",
    "        \n",
    "    def __getitem__(self, k:int):\n",
    "        item,empty_label = self.dataset[k]\n",
    "        \n",
    "        if self.rand_transpose is not None:\n",
    "            val = self.rand_transpose()\n",
    "            item = item.transpose(val)\n",
    "        item = item.pad_to(self.bptt+1)\n",
    "        ((m_x, m_pos), (c_x, c_pos)) = item.to_idx()\n",
    "        return m_x, m_pos, c_x, c_pos\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "def rand_transpose_value(rand_range=(0,24), p=0.5):\n",
    "    if np.random.rand() < p: return np.random.randint(*rand_range)-rand_range[1]//2\n",
    "    return 0\n",
    "\n",
    "class S2SItemList(MusicItemList):\n",
    "    _bunch = MusicDataBunch\n",
    "    def get(self, i):\n",
    "        return MultitrackItem.from_idx(self.items[i], self.vocab)\n",
    "\n",
    "# DATALOADING AND TRANSFORMATIONS\n",
    "# These transforms happen on batch\n",
    "\n",
    "def mask_tfm(b, mask_range, mask_idx, pad_idx, p=0.3):\n",
    "    # mask range (min, max)\n",
    "    # replacement vals - [x_replace, y_replace]. Usually [mask_idx, pad_idx]\n",
    "    # p = replacement probability\n",
    "    x,y = b\n",
    "    x,y = x.clone(),y.clone()\n",
    "    rand = torch.rand(x.shape, device=x.device)\n",
    "    rand[x < mask_range[0]] = 1.0\n",
    "    rand[x >= mask_range[1]] = 1.0\n",
    "    \n",
    "    # p(15%) of words are replaced. Of those p(15%) - 80% are masked. 10% wrong word. 10% unchanged\n",
    "    y[rand > p] = pad_idx # pad unchanged 80%. Remove these from loss/acc metrics\n",
    "    x[rand <= (p*.8)] = mask_idx # 80% = mask\n",
    "    wrong_word = (rand > (p*.8)) & (rand <= (p*.9)) # 10% = wrong word\n",
    "    x[wrong_word] = torch.randint(*mask_range, [wrong_word.sum().item()], device=x.device)\n",
    "    return x, y\n",
    "\n",
    "def mask_lm_tfm_default(b, vocab, mask_p=0.3):\n",
    "    return mask_lm_tfm(b, mask_range=vocab.npenc_range, mask_idx=vocab.mask_idx, pad_idx=vocab.pad_idx, mask_p=mask_p)\n",
    "\n",
    "def mask_lm_tfm_pitchdur(b, vocab, mask_p=0.9):\n",
    "    mask_range = vocab.dur_range if np.random.rand() < 0.5 else vocab.note_range\n",
    "    return mask_lm_tfm(b, mask_range=mask_range, mask_idx=vocab.mask_idx, pad_idx=vocab.pad_idx, mask_p=mask_p)\n",
    "\n",
    "def mask_lm_tfm(b, mask_range, mask_idx, pad_idx, mask_p):\n",
    "    x,y = b\n",
    "    x_lm,x_pos = x[...,0], x[...,1]\n",
    "    y_lm,y_pos = y[...,0], y[...,1]\n",
    "    \n",
    "    # Note: masking y_lm instead of x_lm. Just in case we ever do sequential s2s training\n",
    "    x_msk, y_msk = mask_tfm((y_lm, y_lm), mask_range=mask_range, mask_idx=mask_idx, pad_idx=pad_idx, p=mask_p)\n",
    "    msk_pos = y_pos\n",
    "    \n",
    "    x_dict = { \n",
    "        'msk': { 'x': x_msk, 'pos': msk_pos },\n",
    "        'lm': { 'x': x_lm, 'pos': msk_pos }\n",
    "    }\n",
    "    y_dict = { 'msk': y_msk, 'lm': y_lm }\n",
    "    return x_dict, y_dict\n",
    "\n",
    "def melody_chord_tfm(b):\n",
    "    m,m_pos,c,c_pos = b\n",
    "    \n",
    "    # offset x and y for next word prediction\n",
    "    y_m = m[:,1:]\n",
    "    x_m, m_pos = m[:,:-1], m_pos[:,:-1]\n",
    "    \n",
    "    y_c = c[:,1:]\n",
    "    x_c, c_pos = c[:,:-1], c_pos[:,:-1]\n",
    "    \n",
    "    x_dict = { \n",
    "        'c2m': {\n",
    "            'enc': x_c,\n",
    "            'enc_pos': c_pos,\n",
    "            'dec': x_m,\n",
    "            'dec_pos': m_pos\n",
    "        },\n",
    "        'm2c': {\n",
    "            'enc': x_m,\n",
    "            'enc_pos': m_pos,\n",
    "            'dec': x_c,\n",
    "            'dec_pos': c_pos\n",
    "        }\n",
    "    }\n",
    "    y_dict = {\n",
    "        'c2m': y_m, 'm2c': y_c\n",
    "    }\n",
    "    return x_dict, y_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted config.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted numpy_encode.ipynb.\n",
      "Converted attention_mask.ipynb.\n",
      "Converted env_setup.ipynb.\n",
      "Converted file_processing.ipynb.\n",
      "Converted lamb.ipynb.\n",
      "Converted midifile.ipynb.\n",
      "Converted stacked_dataloader.ipynb.\n",
      "Converted top_k_top_p.ipynb.\n",
      "Converted vocab.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
