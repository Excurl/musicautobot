{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp music_transformer.dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\"Fastai Language Model Databunch modified to work with music\"\n",
    "from fastai.basics import *\n",
    "# from fastai.basic_data import DataBunch\n",
    "from fastai.text.data import LMLabelList\n",
    "from .transform import *\n",
    "from ..vocab import MusicVocab\n",
    "\n",
    "\n",
    "class MusicDataBunch(DataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training a language model.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', no_check:bool=False, bs=64, val_bs:int=None, \n",
    "               num_workers:int=0, device:torch.device=None, collate_fn:Callable=data_collate, \n",
    "               dl_tfms:Optional[Collection[Callable]]=None, bptt:int=70,\n",
    "               preloader_cls=None, shuffle_dl=False, transpose_range=(0,12), **kwargs) -> DataBunch:\n",
    "        \"Create a `TextDataBunch` in `path` from the `datasets` for language modelling.\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        preloader_cls = MusicPreloader if preloader_cls is None else preloader_cls\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        datasets = [preloader_cls(ds, shuffle=(i==0), bs=(bs if i==0 else val_bs), bptt=bptt, transpose_range=transpose_range, **kwargs) \n",
    "                    for i,ds in enumerate(datasets)]\n",
    "        val_bs = bs\n",
    "        dl_tfms = [partially_apply_vocab(tfm, train_ds.vocab) for tfm in listify(dl_tfms)]\n",
    "        dls = [DataLoader(d, b, shuffle=shuffle_dl) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n",
    "        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)\n",
    "    \n",
    "    @classmethod    \n",
    "    def from_folder(cls, path:PathOrStr, extensions='.npy', **kwargs):\n",
    "        files = get_files(path, extensions=extensions, recurse=True);\n",
    "        return cls.from_files(files, path, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_files(cls, files, path, processors=None, split_pct=0.1, \n",
    "                   vocab=None, list_cls=None, **kwargs):\n",
    "        if vocab is None: vocab = MusicVocab.create()\n",
    "        if list_cls is None: list_cls = MusicItemList\n",
    "        src = (list_cls(items=files, path=path, processor=processors, vocab=vocab)\n",
    "                .split_by_rand_pct(split_pct, seed=6)\n",
    "                .label_const(label_cls=LMLabelList))\n",
    "        return src.databunch(**kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def empty(cls, path, **kwargs):\n",
    "        vocab = MusicVocab.create()\n",
    "        src = MusicItemList([], path=path, vocab=vocab, ignore_empty=True).split_none()\n",
    "        return src.label_const(label_cls=LMLabelList).databunch()\n",
    "        \n",
    "def partially_apply_vocab(tfm, vocab):\n",
    "    if 'vocab' in inspect.getfullargspec(tfm).args:\n",
    "        return partial(tfm, vocab=vocab)\n",
    "    return tfm\n",
    "    \n",
    "class MusicItemList(ItemList):\n",
    "    _bunch = MusicDataBunch\n",
    "    \n",
    "    def __init__(self, items:Iterator, vocab:MusicVocab=None, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.vocab = vocab\n",
    "        self.copy_new += ['vocab']\n",
    "    \n",
    "    def get(self, i):\n",
    "        o = super().get(i)\n",
    "        if is_pos_enc(o): \n",
    "            return MusicItem.from_idx(o, self.vocab)\n",
    "        return MusicItem(o, self.vocab)\n",
    "\n",
    "def is_pos_enc(idxenc):\n",
    "    if len(idxenc.shape) == 2 and idxenc.shape[0] == 2: return True\n",
    "    return idxenc.dtype == np.object and idxenc.shape == (2,)\n",
    "\n",
    "class MusicItemProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that transforms numpy files to indexes for training\"\n",
    "    def process_one(self,item):\n",
    "        item = MusicItem.from_npenc(item, vocab=self.vocab)\n",
    "        return item.to_idx()\n",
    "    \n",
    "    def process(self, ds):\n",
    "        self.vocab = ds.vocab\n",
    "        super().process(ds)\n",
    "        \n",
    "class OpenNPFileProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that opens the filenames and read the texts.\"\n",
    "    def process_one(self,item):\n",
    "        return np.load(item, allow_pickle=True) if isinstance(item, Path) else item\n",
    "\n",
    "class Midi2ItemProcessor(PreProcessor):\n",
    "    \"Skips midi preprocessing step. And encodes midi files to MusicItems\"\n",
    "    def process_one(self,item):\n",
    "        item = MusicItem.from_file(item, vocab=self.vocab)\n",
    "        return item.to_idx()\n",
    "    \n",
    "    def process(self, ds):\n",
    "        self.vocab = ds.vocab\n",
    "        super().process(ds)\n",
    "    \n",
    "## For npenc dataset\n",
    "class MusicPreloader(Callback):\n",
    "    \"Transforms the tokens in `dataset` to a stream of contiguous batches for language modelling.\"\n",
    "    \n",
    "    class CircularIndex():\n",
    "        \"Handles shuffle, direction of indexing, wraps around to head tail in the ragged array as needed\"\n",
    "        def __init__(self, length:int, forward:bool): self.idx, self.forward = np.arange(length), forward\n",
    "        def __getitem__(self, i): \n",
    "            return self.idx[ i%len(self.idx) if self.forward else len(self.idx)-1-i%len(self.idx)]\n",
    "        def __len__(self) -> int: return len(self.idx)\n",
    "        def shuffle(self): np.random.shuffle(self.idx)\n",
    "\n",
    "    def __init__(self, dataset:LabelList, lengths:Collection[int]=None, bs:int=32, bptt:int=70, backwards:bool=False, \n",
    "                 shuffle:bool=False, y_offset:int=1, \n",
    "                 transpose_range=None, transpose_p=0.5,\n",
    "                 encode_position=True,\n",
    "                 **kwargs):\n",
    "        self.dataset,self.bs,self.bptt,self.shuffle,self.backwards,self.lengths = dataset,bs,bptt,shuffle,backwards,lengths\n",
    "        self.vocab = self.dataset.vocab\n",
    "        self.bs *= num_distrib() or 1\n",
    "        self.totalToks,self.ite_len,self.idx = int(0),None,None\n",
    "        self.y_offset = y_offset\n",
    "        \n",
    "        self.transpose_range,self.transpose_p = transpose_range,transpose_p\n",
    "        self.encode_position = encode_position\n",
    "        self.bptt_len = self.bptt\n",
    "        \n",
    "        self.allocate_buffers() # needed for valid_dl on distributed training - otherwise doesn't get initialized on first epoch\n",
    "\n",
    "    def __len__(self): \n",
    "        if self.ite_len is None:\n",
    "            if self.lengths is None: self.lengths = np.array([len(item) for item in self.dataset.x])\n",
    "            self.totalToks = self.lengths.sum()\n",
    "            self.ite_len   = self.bs*int( math.ceil( self.totalToks/(self.bptt*self.bs) )) if self.item is None else 1\n",
    "        return self.ite_len\n",
    "\n",
    "    def __getattr__(self,k:str)->Any: return getattr(self.dataset, k)\n",
    "   \n",
    "    def allocate_buffers(self):\n",
    "        \"Create the ragged array that will be filled when we ask for items.\"\n",
    "        if self.ite_len is None: len(self)\n",
    "        self.idx   = MusicPreloader.CircularIndex(len(self.dataset.x), not self.backwards)\n",
    "        \n",
    "        # batch shape = (bs, bptt, 2 - [index, pos]) if encode_position. Else - (bs, bptt)\n",
    "        buffer_len = (2,) if self.encode_position else ()\n",
    "        self.batch = np.zeros((self.bs, self.bptt+self.y_offset) + buffer_len, dtype=np.int64)\n",
    "        self.batch_x, self.batch_y = self.batch[:,0:self.bptt], self.batch[:,self.y_offset:self.bptt+self.y_offset] \n",
    "        #ro: index of the text we're at inside our datasets for the various batches\n",
    "        self.ro    = np.zeros(self.bs, dtype=np.int64)\n",
    "        #ri: index of the token we're at inside our current text for the various batches\n",
    "        self.ri    = np.zeros(self.bs, dtype=np.int)\n",
    "        \n",
    "        # allocate random transpose values. Need to allocate this before hand.\n",
    "        self.transpose_values = self.get_random_transpose_values()\n",
    "        \n",
    "    def get_random_transpose_values(self):\n",
    "        if self.transpose_range is None: return None\n",
    "        n = len(self.dataset)\n",
    "        rt_arr = torch.randint(*self.transpose_range, (n,))-self.transpose_range[1]//2\n",
    "        mask = torch.rand(rt_arr.shape) > self.transpose_p\n",
    "        rt_arr[mask] = 0\n",
    "        return rt_arr\n",
    "\n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        if self.idx is None: self.allocate_buffers()\n",
    "        elif self.shuffle:   \n",
    "            self.ite_len = None\n",
    "            self.idx.shuffle()\n",
    "            self.transpose_values = self.get_random_transpose_values()\n",
    "            self.bptt_len = self.bptt\n",
    "        self.idx.forward = not self.backwards \n",
    "\n",
    "        step = self.totalToks / self.bs\n",
    "        ln_rag, countTokens, i_rag = 0, 0, -1\n",
    "        for i in range(0,self.bs):\n",
    "            #Compute the initial values for ro and ri \n",
    "            while ln_rag + countTokens <= int(step * i):\n",
    "                countTokens += ln_rag\n",
    "                i_rag       += 1\n",
    "                ln_rag       = self.lengths[self.idx[i_rag]]\n",
    "            self.ro[i] = i_rag\n",
    "            self.ri[i] = ( ln_rag - int(step * i - countTokens) ) if self.backwards else int(step * i - countTokens)\n",
    "        \n",
    "    #Training dl gets on_epoch_begin called, val_dl, on_epoch_end\n",
    "    def on_epoch_end(self, **kwargs): self.on_epoch_begin()\n",
    "\n",
    "    def __getitem__(self, k:int):\n",
    "        j = k % self.bs\n",
    "        if j==0:\n",
    "            if self.item is not None: return self.dataset[0]\n",
    "            if self.idx is None: self.on_epoch_begin()\n",
    "                \n",
    "        self.ro[j],self.ri[j] = self.fill_row(not self.backwards, self.dataset.x, self.idx, self.batch[j][:self.bptt_len+self.y_offset], \n",
    "                                              self.ro[j], self.ri[j], overlap=1, lengths=self.lengths)\n",
    "        return self.batch_x[j][:self.bptt_len], self.batch_y[j][:self.bptt_len]\n",
    "\n",
    "    def fill_row(self, forward, items, idx, row, ro, ri, overlap, lengths):\n",
    "        \"Fill the row with tokens from the ragged array. --OBS-- overlap != 1 has not been implemented\"\n",
    "        ibuf = n = 0 \n",
    "        ro  -= 1\n",
    "        while ibuf < row.shape[0]:  \n",
    "            ro   += 1 \n",
    "            ix    = idx[ro]\n",
    "            \n",
    "            item = items[ix]\n",
    "            if self.transpose_values is not None: \n",
    "                item = item.transpose(self.transpose_values[ix].item())\n",
    "                \n",
    "            if self.encode_position:\n",
    "                # Positions are colomn stacked with indexes. This makes it easier to keep in sync\n",
    "                rag = np.stack([item.data, item.position], axis=1)\n",
    "            else:\n",
    "                rag = item.data\n",
    "                \n",
    "            if forward:\n",
    "                ri = 0 if ibuf else ri\n",
    "                n  = min(lengths[ix] - ri, row.shape[0] - ibuf)\n",
    "                row[ibuf:ibuf+n] = rag[ri:ri+n]\n",
    "            else:    \n",
    "                ri = lengths[ix] if ibuf else ri\n",
    "                n  = min(ri, row.size - ibuf) \n",
    "                row[ibuf:ibuf+n] = rag[ri-n:ri][::-1]\n",
    "            ibuf += n\n",
    "        return ro, ri + ((n-overlap) if forward else -(n-overlap))\n",
    "\n",
    "def batch_position_tfm(b):\n",
    "    \"Batch transform for training with positional encoding\"\n",
    "    x,y = b\n",
    "    x = {\n",
    "        'x': x[...,0],\n",
    "        'pos': x[...,1]\n",
    "    }\n",
    "    return x, y[...,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
