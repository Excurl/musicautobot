{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp music_transformer.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *\n",
    "from musicautobot.music_transformer.transform import MusicItem\n",
    "from musicautobot.numpy_encode import SAMPLE_FREQ\n",
    "from musicautobot.utils.top_k_top_p import top_k_top_p\n",
    "from musicautobot.utils.midifile import is_empty_midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MusicLearner(Learner):\n",
    "    def beam_search(self, xb:Tensor, n_words:int, top_k:int=10, beam_sz:int=10, temperature:float=1.,\n",
    "                    ):\n",
    "        \"Return the `n_words` that come after `text` using beam search.\"\n",
    "        if hasattr(self.model, 'reset'): self.model.reset()\n",
    "        self.model.eval()\n",
    "        xb_length = xb.shape[-1]\n",
    "        if xb.shape[0] > 1: xb = xb[0][None]\n",
    "        yb = torch.ones_like(xb)\n",
    "\n",
    "        nodes = None\n",
    "        xb = xb.repeat(top_k, 1)\n",
    "        nodes = xb.clone()\n",
    "        scores = xb.new_zeros(1).float()\n",
    "        with torch.no_grad():\n",
    "            for k in progress_bar(range(n_words), leave=False):\n",
    "                out = F.log_softmax(self.model(xb)[0][:,-1], dim=-1)\n",
    "                values, indices = out.topk(top_k, dim=-1)\n",
    "                scores = (-values + scores[:,None]).view(-1)\n",
    "                indices_idx = torch.arange(0,nodes.size(0))[:,None].expand(nodes.size(0), top_k).contiguous().view(-1)\n",
    "                sort_idx = scores.argsort()[:beam_sz]\n",
    "                scores = scores[sort_idx]\n",
    "                nodes = torch.cat([nodes[:,None].expand(nodes.size(0),top_k,nodes.size(1)),\n",
    "                                indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n",
    "                nodes = nodes.view(-1, nodes.size(2))[sort_idx]\n",
    "                self.model[0].select_hidden(indices_idx[sort_idx])\n",
    "                xb = nodes[:,-1][:,None]\n",
    "        if temperature != 1.: scores.div_(temperature)\n",
    "        node_idx = torch.multinomial(torch.exp(-scores), 1).item()\n",
    "        return [i.item() for i in nodes[node_idx][xb_length:] ]\n",
    "\n",
    "    def predict(self, item:MusicItem, n_words:int=128,\n",
    "                     temperatures:float=(1.0,1.0), min_bars=4,\n",
    "                     top_k=30, top_p=0.6):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        if hasattr(self.model, 'reset'): self.model.reset()\n",
    "        new_idx = []\n",
    "        vocab = self.dls.vocab\n",
    "        x, pos = item.to_tensor(), item.get_pos_tensor()\n",
    "        last_pos = pos[-1] if len(pos) else 0\n",
    "        y = torch.tensor([0])\n",
    "\n",
    "        start_pos = last_pos\n",
    "\n",
    "        sep_count = 0\n",
    "        bar_len = SAMPLE_FREQ * 4 # assuming 4/4 time\n",
    "\n",
    "        repeat_count = 0\n",
    "        \n",
    "        try: encode_position = self.model[0].encode_position\n",
    "        except: encode_position = False\n",
    "\n",
    "        for i in progress_bar(range(n_words), leave=True):\n",
    "            with torch.no_grad():\n",
    "                if encode_position:\n",
    "                    batch = { 'x': x[None], 'pos': pos[None] }\n",
    "                    logits = self.model(batch)[0][-1][-1]\n",
    "                else:\n",
    "                    logits = self.model(x[None])[0][-1][-1]\n",
    "\n",
    "            prev_idx = new_idx[-1] if len(new_idx) else vocab.pad_idx\n",
    "\n",
    "            # Temperature\n",
    "            # Use first temperatures value if last prediction was duration\n",
    "            temperature = temperatures[0] if vocab.is_duration_or_pad(prev_idx) else temperatures[1]\n",
    "            repeat_penalty = max(0, np.log((repeat_count+1)/4)/5) * temperature\n",
    "            temperature += repeat_penalty\n",
    "            if temperature != 1.: logits = logits / temperature\n",
    "                \n",
    "\n",
    "            # Filter\n",
    "            # bar = 16 beats\n",
    "            filter_value = -float('Inf')\n",
    "            if ((last_pos - start_pos) // 16) <= min_bars: logits[vocab.bos_idx] = filter_value\n",
    "\n",
    "            logits = filter_invalid_indexes(logits, prev_idx, vocab, filter_value=filter_value)\n",
    "            logits = top_k_top_p(logits, top_k=top_k, top_p=top_p, filter_value=filter_value)\n",
    "            \n",
    "            # Sample\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx = torch.multinomial(probs, 1).item()\n",
    "\n",
    "            # Update repeat count\n",
    "            num_choices = len(probs.nonzero().view(-1))\n",
    "            if num_choices <= 2: repeat_count += 1\n",
    "            else: repeat_count = repeat_count // 2\n",
    "\n",
    "            if prev_idx==vocab.sep_idx: \n",
    "                duration = idx - vocab.dur_range[0]\n",
    "                last_pos = last_pos + duration\n",
    "\n",
    "                bars_pred = (last_pos - start_pos) // 16\n",
    "                abs_bar = last_pos // 16\n",
    "                # if (bars % 8 == 0) and (bars_pred > min_bars): break\n",
    "                if (i / n_words > 0.80) and (abs_bar % 4 == 0): break\n",
    "\n",
    "\n",
    "            if idx==vocab.bos_idx: \n",
    "                print('Predicted BOS token. Returning prediction...')\n",
    "                break\n",
    "\n",
    "            new_idx.append(idx)\n",
    "            x = x.new_tensor([idx])\n",
    "            pos = pos.new_tensor([last_pos])\n",
    "\n",
    "        pred = MusicItem(np.array(new_idx), vocab)\n",
    "        full = item.append(pred)\n",
    "        return pred, full\n",
    "    \n",
    "# High level prediction functions from midi file\n",
    "def predict_from_midi(learn, midi=None, n_words=400, \n",
    "                      temperatures=(1.0,1.0), top_k=30, top_p=0.6, seed_len=None, **kwargs):\n",
    "    vocab = learn.dls.vocab\n",
    "    seed = MusicItem.from_file(midi, vocab) if not is_empty_midi(midi) else MusicItem.empty(vocab)\n",
    "    if seed_len is not None: seed = seed.trim_to_beat(seed_len)\n",
    "\n",
    "    pred, full = learn.predict(seed, n_words=n_words, temperatures=temperatures, top_k=top_k, top_p=top_p, **kwargs)\n",
    "    return full\n",
    "\n",
    "def filter_invalid_indexes(res, prev_idx, vocab, filter_value=-float('Inf')):\n",
    "    if vocab.is_duration_or_pad(prev_idx):\n",
    "        res[list(range(*vocab.dur_range))] = filter_value\n",
    "    else:\n",
    "        res[list(range(*vocab.note_range))] = filter_value\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted config.ipynb.\n",
      "Converted Train-before_cleanup.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted Train.ipynb.\n",
      "Converted dataloader.ipynb.\n",
      "Converted learner.ipynb.\n",
      "Converted model.ipynb.\n",
      "Converted Train-Scratch.ipynb.\n",
      "Converted dataloader-reference.ipynb.\n",
      "Converted dataloader-v1.ipynb.\n",
      "Converted transform.ipynb.\n",
      "Converted numpy_encode.ipynb.\n",
      "Converted attention_mask.ipynb.\n",
      "Converted env_setup.ipynb.\n",
      "Converted file_processing.ipynb.\n",
      "Converted lamb.ipynb.\n",
      "Converted midifile.ipynb.\n",
      "Converted stacked_dataloader.ipynb.\n",
      "Converted top_k_top_p.ipynb.\n",
      "Converted vocab.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(recursive=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
