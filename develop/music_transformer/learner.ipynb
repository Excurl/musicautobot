{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp music_transformer.learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.basics import *\n",
    "from fastai.text.learner import LanguageLearner, get_language_model, _model_meta\n",
    "from .model import *\n",
    "from .transform import MusicItem\n",
    "from ..numpy_encode import SAMPLE_FREQ\n",
    "from ..utils.top_k_top_p import top_k_top_p\n",
    "from ..utils.midifile import is_empty_midi\n",
    "\n",
    "_model_meta[MusicTransformerXL] = _model_meta[TransformerXL] # copy over fastai's model metadata\n",
    "\n",
    "def music_model_learner(data:DataBunch, arch=MusicTransformerXL, config:dict=None, drop_mult:float=1.,\n",
    "                        pretrained_path:PathOrStr=None, **learn_kwargs) -> 'LanguageLearner':\n",
    "    \"Create a `Learner` with a language model from `data` and `arch`.\"\n",
    "    meta = _model_meta[arch]\n",
    "\n",
    "    if pretrained_path: \n",
    "        state = torch.load(pretrained_path, map_location='cpu')\n",
    "        if config is None: config = state['config']\n",
    "        \n",
    "    model = get_language_model(arch, len(data.vocab.itos), config=config, drop_mult=drop_mult)\n",
    "    learn = MusicLearner(data, model, split_func=meta['split_lm'], **learn_kwargs)\n",
    "\n",
    "    if pretrained_path: \n",
    "        get_model(model).load_state_dict(state['model'], strict=False)\n",
    "        if not hasattr(learn, 'opt'): learn.create_opt(defaults.lr, learn.wd)\n",
    "        try:    learn.opt.load_state_dict(state['opt'])\n",
    "        except: pass\n",
    "        del state\n",
    "        gc.collect()\n",
    "\n",
    "    return learn\n",
    "\n",
    "# Predictions\n",
    "from fastai import basic_train # for predictions\n",
    "class MusicLearner(LanguageLearner):\n",
    "    def save(self, file:PathLikeOrBinaryStream=None, with_opt:bool=True, config=None):\n",
    "        \"Save model and optimizer state (if `with_opt`) with `file` to `self.model_dir`. `file` can be file-like (file or buffer)\"\n",
    "        out_path = super().save(file, return_path=True, with_opt=with_opt)\n",
    "        if config and out_path:\n",
    "            state = torch.load(out_path)\n",
    "            state['config'] = config\n",
    "            torch.save(state, out_path)\n",
    "            del state\n",
    "            gc.collect()\n",
    "        return out_path\n",
    "\n",
    "    def beam_search(self, xb:Tensor, n_words:int, top_k:int=10, beam_sz:int=10, temperature:float=1.,\n",
    "                    ):\n",
    "        \"Return the `n_words` that come after `text` using beam search.\"\n",
    "        self.model.reset()\n",
    "        self.model.eval()\n",
    "        xb_length = xb.shape[-1]\n",
    "        if xb.shape[0] > 1: xb = xb[0][None]\n",
    "        yb = torch.ones_like(xb)\n",
    "\n",
    "        nodes = None\n",
    "        xb = xb.repeat(top_k, 1)\n",
    "        nodes = xb.clone()\n",
    "        scores = xb.new_zeros(1).float()\n",
    "        with torch.no_grad():\n",
    "            for k in progress_bar(range(n_words), leave=False):\n",
    "                out = F.log_softmax(self.model(xb)[0][:,-1], dim=-1)\n",
    "                values, indices = out.topk(top_k, dim=-1)\n",
    "                scores = (-values + scores[:,None]).view(-1)\n",
    "                indices_idx = torch.arange(0,nodes.size(0))[:,None].expand(nodes.size(0), top_k).contiguous().view(-1)\n",
    "                sort_idx = scores.argsort()[:beam_sz]\n",
    "                scores = scores[sort_idx]\n",
    "                nodes = torch.cat([nodes[:,None].expand(nodes.size(0),top_k,nodes.size(1)),\n",
    "                                indices[:,:,None].expand(nodes.size(0),top_k,1),], dim=2)\n",
    "                nodes = nodes.view(-1, nodes.size(2))[sort_idx]\n",
    "                self.model[0].select_hidden(indices_idx[sort_idx])\n",
    "                xb = nodes[:,-1][:,None]\n",
    "        if temperature != 1.: scores.div_(temperature)\n",
    "        node_idx = torch.multinomial(torch.exp(-scores), 1).item()\n",
    "        return [i.item() for i in nodes[node_idx][xb_length:] ]\n",
    "\n",
    "    def predict(self, item:MusicItem, n_words:int=128,\n",
    "                     temperatures:float=(1.0,1.0), min_bars=4,\n",
    "                     top_k=30, top_p=0.6):\n",
    "        \"Return the `n_words` that come after `text`.\"\n",
    "        self.model.reset()\n",
    "        new_idx = []\n",
    "        vocab = self.data.vocab\n",
    "        x, pos = item.to_tensor(), item.get_pos_tensor()\n",
    "        last_pos = pos[-1] if len(pos) else 0\n",
    "        y = torch.tensor([0])\n",
    "\n",
    "        start_pos = last_pos\n",
    "\n",
    "        sep_count = 0\n",
    "        bar_len = SAMPLE_FREQ * 4 # assuming 4/4 time\n",
    "        vocab = self.data.vocab\n",
    "\n",
    "        repeat_count = 0\n",
    "        if hasattr(self.model[0], 'encode_position'):\n",
    "            encode_position = self.model[0].encode_position\n",
    "        else: encode_position = False\n",
    "\n",
    "        for i in progress_bar(range(n_words), leave=True):\n",
    "            with torch.no_grad():\n",
    "                if encode_position:\n",
    "                    batch = { 'x': x[None], 'pos': pos[None] }\n",
    "                    logits = self.model(batch)[0][-1][-1]\n",
    "                else:\n",
    "                    logits = self.model(x[None])[0][-1][-1]\n",
    "\n",
    "            prev_idx = new_idx[-1] if len(new_idx) else vocab.pad_idx\n",
    "\n",
    "            # Temperature\n",
    "            # Use first temperatures value if last prediction was duration\n",
    "            temperature = temperatures[0] if vocab.is_duration_or_pad(prev_idx) else temperatures[1]\n",
    "            repeat_penalty = max(0, np.log((repeat_count+1)/4)/5) * temperature\n",
    "            temperature += repeat_penalty\n",
    "            if temperature != 1.: logits = logits / temperature\n",
    "                \n",
    "\n",
    "            # Filter\n",
    "            # bar = 16 beats\n",
    "            filter_value = -float('Inf')\n",
    "            if ((last_pos - start_pos) // 16) <= min_bars: logits[vocab.bos_idx] = filter_value\n",
    "\n",
    "            logits = filter_invalid_indexes(logits, prev_idx, vocab, filter_value=filter_value)\n",
    "            logits = top_k_top_p(logits, top_k=top_k, top_p=top_p, filter_value=filter_value)\n",
    "            \n",
    "            # Sample\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx = torch.multinomial(probs, 1).item()\n",
    "\n",
    "            # Update repeat count\n",
    "            num_choices = len(probs.nonzero().view(-1))\n",
    "            if num_choices <= 2: repeat_count += 1\n",
    "            else: repeat_count = repeat_count // 2\n",
    "\n",
    "            if prev_idx==vocab.sep_idx: \n",
    "                duration = idx - vocab.dur_range[0]\n",
    "                last_pos = last_pos + duration\n",
    "\n",
    "                bars_pred = (last_pos - start_pos) // 16\n",
    "                abs_bar = last_pos // 16\n",
    "                # if (bars % 8 == 0) and (bars_pred > min_bars): break\n",
    "                if (i / n_words > 0.80) and (abs_bar % 4 == 0): break\n",
    "\n",
    "\n",
    "            if idx==vocab.bos_idx: \n",
    "                print('Predicted BOS token. Returning prediction...')\n",
    "                break\n",
    "\n",
    "            new_idx.append(idx)\n",
    "            x = x.new_tensor([idx])\n",
    "            pos = pos.new_tensor([last_pos])\n",
    "\n",
    "        pred = vocab.to_music_item(np.array(new_idx))\n",
    "        full = item.append(pred)\n",
    "        return pred, full\n",
    "    \n",
    "# High level prediction functions from midi file\n",
    "def predict_from_midi(learn, midi=None, n_words=400, \n",
    "                      temperatures=(1.0,1.0), top_k=30, top_p=0.6, seed_len=None, **kwargs):\n",
    "    vocab = learn.data.vocab\n",
    "    seed = MusicItem.from_file(midi, vocab) if not is_empty_midi(midi) else MusicItem.empty(vocab)\n",
    "    if seed_len is not None: seed = seed.trim_to_beat(seed_len)\n",
    "\n",
    "    pred, full = learn.predict(seed, n_words=n_words, temperatures=temperatures, top_k=top_k, top_p=top_p, **kwargs)\n",
    "    return full\n",
    "\n",
    "def filter_invalid_indexes(res, prev_idx, vocab, filter_value=-float('Inf')):\n",
    "    if vocab.is_duration_or_pad(prev_idx):\n",
    "        res[list(range(*vocab.dur_range))] = filter_value\n",
    "    else:\n",
    "        res[list(range(*vocab.note_range))] = filter_value\n",
    "    return res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
