# AUTOGENERATED! DO NOT EDIT! File to edit: develop/music_transformer/dataloader.ipynb (unless otherwise specified).

__all__ = ['Midi2ItemTfm', 'MusicItemTfm', 'mi2tensor', 'rand_transpose', 'batch_position_tfm']

# Cell
"Fastai Language Model Databunch modified to work with music"

# Cell
from ..imports import *
from .transform import *
from ..vocab import MusicVocab

import random
from fastai.basics import *
from fastai.text.all import *

# Cell
class Midi2ItemTfm(Transform):
    "Skips midi preprocessing step. And encodes midi files to MusicItems"
    def __init__(self,vocab):
        self.vocab = vocab

    def encodes(self, o):
        return MusicItem.from_file(o, vocab=self.vocab)

class MusicItemTfm(Transform):
    "`PreProcessor` that transforms numpy files to indexes for training"
    def __init__(self,vocab):
        self.vocab = vocab

    def encodes(self, f):
        npitem = np.load(f, allow_pickle=True) if isinstance(f, Path) else f
        miitem = MusicItem.from_npenc(npitem, vocab=self.vocab)
        return miitem

# Cell
def mi2tensor(mi): return np.stack(mi.to_idx()).T

def rand_transpose(mi, steps=6, p=0.5):
    if random.random() >= p: return mi
    val = random.randint(-steps, steps)
    return mi.transpose(val)

def batch_position_tfm(b):
    "Batch transform for training with positional encoding"
    x,y = b
    x = {
        'x': x[...,0],
        'pos': x[...,1]
    }
    return x, y[...,0]

# @delegates()
# class MusicItemDataLoader(LMDataLoader):
#     def __init__(self, dataset, trange=6, tp=0.5, encode_position=False, **kwargs):
#         store_attr('trange,tp,encode_position')
#         super().__init__(dataset, **kwargs)

#     def make_chunks(self):
#         transpose_tfm = partial(rand_transpose, steps=self.trange, p=self.tp)
#         tensor_tfm = mi2tensor if self.encode_position else lambda x: x.data
#         pipeline = Pipeline([transpose_tfm, tensor_tfm])

#         self.chunks = Chunks(list(map(pipeline, self.items)), self.lens)

#     def create_item(self, seq):
#         item = super().create_item(seq)
#         return batch_position_tfm(item) if self.encode_position else item