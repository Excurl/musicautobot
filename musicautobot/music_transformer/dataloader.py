# AUTOGENERATED! DO NOT EDIT! File to edit: develop/music_transformer/dataloader.ipynb (unless otherwise specified).

__all__ = ['Midi2ItemTfm', 'MusicItemTfm', 'mi2tensor', 'rand_transpose', 'batch_position_tfm', 'MusicItemDataLoader']

# Cell
"Fastai Language Model Databunch modified to work with music"

# Cell
from ..imports import *
from .transform import *
from ..vocab import MusicVocab

import random
from fastai.basics import *
from fastai.text.all import *

# Cell
class Midi2ItemTfm(Transform):
    "Skips midi preprocessing step. And encodes midi files to MusicItems"
    def __init__(self,vocab):
        self.vocab = vocab

    def encodes(self, o):
        return MusicItem.from_file(o, vocab=self.vocab)

class MusicItemTfm(Transform):
    "`PreProcessor` that transforms numpy files to indexes for training"
    def __init__(self,vocab):
        self.vocab = vocab

    def encodes(self, f):
        npitem = np.load(f, allow_pickle=True) if isinstance(f, Path) else f
        miitem = MusicItem.from_npenc(npitem, vocab=self.vocab)
        return miitem.to_idx()

# Cell
def mi2tensor(mi): return np.stack([mi.data, mi.position]).T

def rand_transpose(mi, steps=6, p=0.5):
    if random.random() >= p: return mi
    val = random.randint(-steps, steps)
    return mi.transpose(val)

def batch_position_tfm(b):
    "Batch transform for training with positional encoding"
    x,y = b
    x = {
        'x': x[...,0],
        'pos': x[...,1]
    }
    return x, y[...,0]

@delegates()
class MusicItemDataLoader(LMDataLoader):
    def __init__(self, dataset, trange=6, tp=0.5, **kwargs):
        self.trange = trange
        self.tp = tp
        super().__init__(dataset, **kwargs)

    def make_chunks(self):
        items = [mi2tensor(rand_transpose(mi, self.trange, self.tp)) for mi in self.items]
        self.chunks = Chunks(items, self.lens)

    def create_item(self, seq):
        return batch_position_tfm(super().create_item(seq))